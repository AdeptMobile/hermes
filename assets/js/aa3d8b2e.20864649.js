"use strict";(self.webpackChunkhermes_website=self.webpackChunkhermes_website||[]).push([[611],{3905:function(e,t,n){n.d(t,{Zo:function(){return c},kt:function(){return m}});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),h=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=h(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},p=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=h(n),p=r,m=u["".concat(l,".").concat(p)]||u[p]||d[p]||i;return n?a.createElement(m,o(o({ref:t},c),{},{components:n})):a.createElement(m,o({ref:t},c))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=p;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:r,o[1]=s;for(var h=2;h<i;h++)o[h]=n[h];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}p.displayName="MDXCreateElement"},8070:function(e,t,n){n.r(t),n.d(t,{assets:function(){return c},contentTitle:function(){return l},default:function(){return m},frontMatter:function(){return s},metadata:function(){return h},toc:function(){return u}});var a=n(3117),r=n(102),i=(n(7294),n(3905)),o=["components"],s={id:"hades",title:"The Hades Garbage Collector"},l=void 0,h={unversionedId:"hades",id:"hades",title:"The Hades Garbage Collector",description:"Hades is a garbage collector for Hermes that aims to improve pause times by an",source:"@site/../doc/Hades.md",sourceDirName:".",slug:"/hades",permalink:"/docs/hades",draft:!1,editUrl:"https://github.com/facebook/hermes/blob/HEAD/website/../doc/Hades.md",tags:[],version:"current",lastUpdatedAt:1649112449,formattedLastUpdatedAt:"Apr 4, 2022",frontMatter:{id:"hades",title:"The Hades Garbage Collector"},sidebar:"docs",previous:{title:"The GenGC Garbage Collector",permalink:"/docs/gengc"},next:{title:"Modules",permalink:"/docs/modules"}},c={},u=[{value:"Check Which GC is Used",id:"check-which-gc-is-used",level:2},{value:"Freelist Allocator",id:"freelist-allocator",level:2},{value:"Mark Phase",id:"mark-phase",level:2},{value:"Write Barriers",id:"write-barriers",level:3},{value:"Complete Marking",id:"complete-marking",level:2},{value:"WeakRef Read Barriers",id:"weakref-read-barriers",level:3},{value:"Sweep Phase",id:"sweep-phase",level:2},{value:"Compact Phase",id:"compact-phase",level:2},{value:"Incremental Mode",id:"incremental-mode",level:2}],d={toc:u},p="wrapper";function m(e){var t=e.components,n=(0,r.Z)(e,o);return(0,i.kt)(p,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("p",null,"Hades is a garbage collector for Hermes that aims to improve pause times by an\norder of magnitude over GenGC. The main principle Hades uses to achieve those\nlow pause times is that most of the garbage collection work happens in a\nbackground thread concurrently with the interpreter running JavaScript code.\nThis is distinct from GenGC, which only runs on a single thread which is shared\nwith the interpreter."),(0,i.kt)("h1",{id:"enabling-hades"},"Enabling Hades"),(0,i.kt)("p",null,"In local builds on the command line using CMake (which forwards to CMake), Hades\nis the default GC used, and currently the only GC supported for production use.\nThe GC being used is controlled by the CMake variable ",(0,i.kt)("inlineCode",{parentName:"p"},"-DHERMESVM_GCKIND=value"),"."),(0,i.kt)("p",null,"To use a pre-built package of Hermes with Hades enabled, check the\n",(0,i.kt)("a",{parentName:"p",href:"https://github.com/facebook/hermes/releases"},"Releases page on Github"),".\nAs of right now, there aren't any available, but we'll be making one available\nwith v0.8 and later."),(0,i.kt)("h2",{id:"check-which-gc-is-used"},"Check Which GC is Used"),(0,i.kt)("p",null,"If you want to know what GC is being used in your application, you can find out\nwith some JS:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-js"},"const gcName = HermesInternal.getRuntimeProperties().GC;\n// If you're running Hermes on the command line, use print.\nprint(gcName);\n// If you're running Hermes in some kind of framework like React Native,\n// console.log should exist.\nconsole.log(gcName);\n")),(0,i.kt)("p",null,"This will print one of:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},'"hades (concurrent)"'),": You're using Hades in concurrent mode"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("inlineCode",{parentName:"li"},'"hades (incremental)"'),": You're using Hades in ",(0,i.kt)("a",{parentName:"li",href:"#incremental-mode"},"incremental mode"))),(0,i.kt)("h1",{id:"basics"},"Basics"),(0,i.kt)("p",null,"Most of the basic heap structure of Hades is similar to GenGC, so it is\nrecommended to read the ",(0,i.kt)("a",{parentName:"p",href:"/docs/gengc"},"GenGC Documentation")," first, in particular\nthe following sections:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/gengc#heap-segments"},"Heap Segments")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/gengc#object-types"},"Object Types")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/gengc#generations"},"Generations")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"/docs/gengc#write-barriers"},"Write Barriers"))),(0,i.kt)("h1",{id:"generations"},"Generations"),(0,i.kt)("p",null,"Similarly to GenGC, Hades also has two generations: the ",(0,i.kt)("strong",{parentName:"p"},"Young Generation"),"\n(YG) and ",(0,i.kt)("strong",{parentName:"p"},"Old Generation")," (OG). Allocations go initially into YG, and if they\nsurvive the first collection they go into OG. YG works exactly the same as\nGenGC, but OG has a different allocation strategy that allows for gaps."),(0,i.kt)("h2",{id:"freelist-allocator"},"Freelist Allocator"),(0,i.kt)("p",null,"Hades's OG is a list of heap segments, and each heap segment maintains a\n",(0,i.kt)("strong",{parentName:"p"},"Free List")," of empty space. Each ",(0,i.kt)("strong",{parentName:"p"},"Free List Cell")," points to the next cell,\ncalled an explicit free list. This is opposed to an implicit free list, where\nthe length is used to traverse both free and used cells. A free list is used\nbecause it allows empty space to be left where it is, without requiring\ncompaction. This is a requirement for concurrent allocations and sweeping."),(0,i.kt)("p",null,"Furthermore, the free list is ",(0,i.kt)("strong",{parentName:"p"},"size-segregated"),", meaning each size class gets\na separate free list. In other words, cells of size ",(0,i.kt)("inlineCode",{parentName:"p"},"N")," only point to other\ncells of size ",(0,i.kt)("inlineCode",{parentName:"p"},"N"),". This allows an allocation of size ",(0,i.kt)("inlineCode",{parentName:"p"},"N")," to be satisfied\ninstantly with the head of the free list. Each free list head is stored at an\nindex in a fixed-size array for small cell sizes. These are known as\n",(0,i.kt)("strong",{parentName:"p"},"buckets"),"."),(0,i.kt)("p",null,"Hades does not do any rounding up of sizes beyond the required heap alignment\nof 8 bytes. This means there is one bucket for each multiple of 8, up to 2048\nbytes. From 2048 bytes to the maximum heap segment size (4 MiB) the buckets go\nby powers of 2. For large buckets, we store cells that are greater than or equal\nto the size bucket, but less than the next power of 2. Cells that need less than\nthe size of the free list cell ",(0,i.kt)("strong",{parentName:"p"},"carve")," out a small piece of the cell, and put\nthe remaining piece on a the free list corresponding to its new size."),(0,i.kt)("p",null,"Due to having these free lists be per-segment, we need a quick way to find which\nsegment has free space for a given size. We do this with a series of bit arrays,\nwhere bits are flipped to 0 as a free list is exhausted in a segment, and\nflipped back to 1 when sweeping frees some cells. We have per-segment free lists\nso that sweeping and compaction (which also operate on a per-segment basis) can\ndestroy them efficiently and create a new list. It can do this to easily\ncoalesce adjacent free regions."),(0,i.kt)("h1",{id:"collection-cycles"},"Collection Cycles"),(0,i.kt)("p",null,"Hades has two different types of collections: a YG collection (YG GC) and an\nOG collection (OG GC). The former is almost exactly the same as GenGC's, so we\nwon't repeat it here. The OG GC is very different though, because it runs\nconcurrently in a background thread."),(0,i.kt)("p",null,"For the purposes of distinguishing these two threads, we'll name them as\nfollows:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"Mutator Thread"),": The thread running the JS interpreter"),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("strong",{parentName:"li"},"GC Thread"),": The thread running any GC operations such as marking or\nsweeping")),(0,i.kt)("p",null,"Note that currently there is only ever a single GC thread at any point in time.\nWe also cache the thread and reuse it instead of making a new one for each\ncollection."),(0,i.kt)("p",null,"There are three different locks used throughout the GC:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"The ",(0,i.kt)("strong",{parentName:"li"},"GC Mutex")," is used to protect structures like mark bits, card tables,\nand the free lists"),(0,i.kt)("li",{parentName:"ul"},"The ",(0,i.kt)("strong",{parentName:"li"},"WeakRef Mutex")," is used to protect structures used during weak ref\nmarking"),(0,i.kt)("li",{parentName:"ul"},"The ",(0,i.kt)("strong",{parentName:"li"},"Write Barrier Mutex")," is used to protect a small buffer used by write\nbarriers and concurrent marking")),(0,i.kt)("p",null,"The GC mutex is used to protect most things, as they tend to all be accessed at\nthe same time. There was no need for finer grained locks yet, with the exception\nof the write barrier mutex because write barriers are executed all the time."),(0,i.kt)("p",null,"An OG GC is started once the OG is about 75% full. We start it a bit early so\nthat it can complete sweeping before reaching 100% full and avoid blocking any\nallocations."),(0,i.kt)("h2",{id:"mark-phase"},"Mark Phase"),(0,i.kt)("p",null,"The first step of an OG GC is to mark all of the roots of the object graph.\nWe only ever start an OG GC when YG is empty, so there's no need to mark any of\nYG."),(0,i.kt)("p",null,"Marking an object consists of the following steps:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Using mark bits, check if an object has been visited already"),(0,i.kt)("li",{parentName:"ul"},"If it has been visited already, there's nothing to do"),(0,i.kt)("li",{parentName:"ul"},"If not, push it onto a ",(0,i.kt)("strong",{parentName:"li"},"mark stack")," that will be drained later"),(0,i.kt)("li",{parentName:"ul"},"Set its mark bit"),(0,i.kt)("li",{parentName:"ul"},"If the object pointed to is a WeakMap, put it onto a separate stack\n(see ",(0,i.kt)("a",{parentName:"li",href:"/docs/gengc#weak-map-resolution"},"Weak Map Resolution"),")")),(0,i.kt)("p",null,"Draining the mark stack works as follows:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Acquire a lock on the GC mutex"),(0,i.kt)("li",{parentName:"ul"},"Check if the write barrier buffer has objects that need to be marked, if so,\nadd them to the mark stack"),(0,i.kt)("li",{parentName:"ul"},"While we've marked fewer than a certain number of bytes, defaults to 8 KiB",(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Pull one object off the mark stack"),(0,i.kt)("li",{parentName:"ul"},"Get its type metadata (see ",(0,i.kt)("a",{parentName:"li",href:"/docs/gengc#object-types"},"Object Types"),")"),(0,i.kt)("li",{parentName:"ul"},"Use the metadata to find pointers to other objects"),(0,i.kt)("li",{parentName:"ul"},"Those other objects will be pushed on the stack"))),(0,i.kt)("li",{parentName:"ul"},"Release the lock on the GC mutex")),(0,i.kt)("p",null,"This can run almost entirely uninterrupted on the background thread since very\nfew things need to acquire the GC mutex. The most common way to interrupt\nmarking is when YG fills up, as it requires the GC mutex in order to evacuate\nYG."),(0,i.kt)("h3",{id:"write-barriers"},"Write Barriers"),(0,i.kt)("p",null,"There's an important race condition to consider when thinking about concurrent\nmarking: what happens if a pointer is modified while we're reading it?"),(0,i.kt)("p",null,"There are two different races that are possible here:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},'A non-atomic read of the pointer might race with a non-atomic write, and the\nreads or writes might "tear" (meaning you see only part of the write)'),(0,i.kt)("li",{parentName:"ul"},"You might miss marking the old value or the new value")),(0,i.kt)("p",null,"The first is handled on 64-bit platforms because all of the reads are of a 64\nbit value, which can be atomically handled cheaply on a 64-bit CPU. See the\n",(0,i.kt)("a",{parentName:"p",href:"#incremental-mode"},"Incremental Mode")," section for what we do on a 32-bit CPU."),(0,i.kt)("p",null,"The second problem is harder to solve. If we see the old value, and the new\nobject isn't marked anywhere else, we would accidentally think it's garbage and\ncollect it! Alternatively, if we see the new value, the old value won't be\nmarked. This would be a problem if the old pointer was moved from one object to\nanother, but we had already marked the second object."),(0,i.kt)("p",null,'In order to fix this, we need to know when a pointer is modified during\nconcurrent marking. Hades implements this through an additional write barrier.\nThis write barrier is based on a principle called "Snapshot at the Beginning"\n(SATB). The principle is that we want to collect the OG based on a snapshot\nof the heap when the collection began. Which means if a pointer is changed, we\nwant to make sure we mark the old value instead of the new value.'),(0,i.kt)("p",null,'This might feel counter-intuitive compared to the more common alternative\napproach known as "Incremental Update" (IU), where the new value is marked. The\nreason Hades uses SATB instead is that it has a nice guarantee: you\'ll never\nneed to revisit any object you have already marked. This means there is a finite\nupper bound on the amount of work marking has to do. IU write barrier based\nsystems often have a race near the end, where the GC thread needs to pause the\nmutator thread to try and complete marking as fast as possible. If it exceeds\na time quota, it resumes the mutator and tries again later. We avoid this\ncomplexity with our SATB barrier.'),(0,i.kt)("p",null,"A second benefit of SATB is that we can treat any allocations made into OG\nbetween the start and end of the collection as alive by default, without\nneeding to mark them."),(0,i.kt)("p",null,"And the final benefit of SATB is that there is never a need to mark the roots\nagain to finish a collection, as their old values were handled at the start\nof the collection while the mutator was paused."),(0,i.kt)("p",null,'The barrier works by pushing the old value onto a small fixed size buffer, which\nhas space for 128 elements. Once it fills up, the Write Barrier Lock is taken to\n"flush" the buffer into a separate mark stack used by the concurrent marker.\nThis means a lock is only taken every 128 write barriers. It uses a separate\nmutex from the GC mutex to ensure a write barrier is not blocked for very long\nif the GC thread happens to be reading from the separate mark stack.'),(0,i.kt)("h2",{id:"complete-marking"},"Complete Marking"),(0,i.kt)("p",null,"Once the mark stack is empty, there are a few details that need to be handled in\norder to complete marking and move on to sweeping:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Flush any remaining write barrier pointers left"),(0,i.kt)("li",{parentName:"ul"},"Handle WeakMap resolution"),(0,i.kt)("li",{parentName:"ul"},"Fix weak references (WeakRefs)")),(0,i.kt)("p",null,"Handling these things can be very tricky concurrently, so in order to prevent\nbugs and infinite loops, we pause the mutator during this time. Even though SATB\nwrite barriers don't require the mutator to pause, these other operations do\nrequire a pause, so unfortunately this is still required."),(0,i.kt)("p",null,"Flushing the remaining write barrier pointers just means copying the pointers\ninto the mark stack and draining it one more time. This could potentially take\na very long time, but in practice that is exceedingly rare."),(0,i.kt)("p",null,"WeakMap resolution is handled in the same way that GenGC handles it. We do this\nduring a mutator pause mostly because we didn't want to rewrite the algorithm\nto work in a concurrent context, as it's already very complicated on its own."),(0,i.kt)("p",null,"Weak References also need to be cleared if they point to something that is\nnow garbage, and this is much easier to do with the mutator paused. Otherwise\nthe mutator would need a lock to read a weak reference value. This could be\nimproved to simply be an atomic operation in the future, but for now this can't\nbe atomic."),(0,i.kt)("p",null,"Once that's all taken care of, we can move on to sweeping."),(0,i.kt)("h3",{id:"weakref-read-barriers"},"WeakRef Read Barriers"),(0,i.kt)("p",null,"There's a caveat to mention about WeakRefs and the SATB barrier. If you read a\npointer out of a weak reference and store it in an object on the heap, SATB\nwon't record the change, and the object might not be found reachable. Something\nsimilar can happen if a weak ref is read and placed into a root."),(0,i.kt)("p",null,"To fix this, we have WeakRef reads perform a barrier on the pointer being read.\nThis conservatively assumes the pointer being read is alive. WeakRefs are not\nread from that often, so this was deemed an acceptable cost."),(0,i.kt)("p",null,"Note that there also weak roots, such as the HiddenClass cache stored in each\nCodeBlock. These do not perform a read barrier, specifically because they are\nonly ever used for comparisons. They never produce a pointer that was otherwise\ndead. A possible simplification of this in the future could use a HiddenClass ID\ninstead of a pointer, as it achieves the same effect without requiring a special\ncase."),(0,i.kt)("h2",{id:"sweep-phase"},"Sweep Phase"),(0,i.kt)("p",null,"Once complete reachability information is known, the OG GC turns off the\nSATB barriers. The sweeper iterates over one segment at a time, allowing the\nmutator to interleave. This is specifically allowed because the sweeper only\never modifies garbage objects that aren't used, therefore there's no races.\nIt holds the GC mutex to prevent YG from allocating into the OG while it's\nbeing swept."),(0,i.kt)("p",null,"The process works as follows:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Acquire a lock on the GC mutex"),(0,i.kt)("li",{parentName:"ul"},"Clear one heap segment's free list"),(0,i.kt)("li",{parentName:"ul"},"Iterate linearly over cells, using the embedded length to skip over live cells"),(0,i.kt)("li",{parentName:"ul"},"Check if a cell is new garbage using its type tag"),(0,i.kt)("li",{parentName:"ul"},"If it is not new garbage, continue to the next cell"),(0,i.kt)("li",{parentName:"ul"},"If it is new garbage, turn it into a free list cell."),(0,i.kt)("li",{parentName:"ul"},"Contiguous unused regions are added as a single region onto the new free list"),(0,i.kt)("li",{parentName:"ul"},"Once all cells in the segment have been processed, release the lock")),(0,i.kt)("p",null,"Once that process is completed for every heap segment, sweeping completes and\nthe OG collection is over."),(0,i.kt)("h2",{id:"compact-phase"},"Compact Phase"),(0,i.kt)("p",null,"Compacting live memory to be closer together is still a beneficial concept in\nHades, as it allows us to return unused memory to the OS, and reduces the\nfragmentation of the free lists for mostly empty heap segments. Implementing it\nis more tricky than GenGC though, as we can't modify pointers concurrently with\nthe mutator thread."),(0,i.kt)("p",null,"Due to these restrictions, we can currently only compact a single segment\n(called the compactee) for each full collection. Compaction runs as part of the\ncollection cycle and flows as follows:"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},"At the start of an OG collection, determine whether the heap is currently\nlarger than its target size. If so, select and record a segment to compact."),(0,i.kt)("li",{parentName:"ol"},"Write barriers start dirtying cards for pointers pointing into the\ncompaction candidate. This will continue until the compaction is fully complete."),(0,i.kt)("li",{parentName:"ol"},"Marking begins. During marking, we dirty cards in the card table\ncorresponding to any on-heap pointers that point into the compaction candidate.\nAny YG collection that occurs during marking needs special care. Promoted\nobjects will not be scanned by the OG since they are allocated as marked, so\nthey need to be scanned for compactee pointers after they have been promoted.\nFurthermore, the card table cannot be cleared at the end of the YG collection,\nsince that would erase information from the ongoing compaction."),(0,i.kt)("li",{parentName:"ol"},"During the STW pause, the internal state of the GC is updated to signal that\nall pointers into the compactee have been marked, and that the next YG\ncollection should complete the compaction."),(0,i.kt)("li",{parentName:"ol"},"Sweeping. The segment identified for compaction will not be swept, however\ncompaction may take place during sweeping if the next YG collection starts\nbefore sweeping is complete. Note that write barriers will continue to be active\nuntil compaction is complete, since new pointers from the OG into the compactee\nmay be added."),(0,i.kt)("li",{parentName:"ol"},"Compaction. The next young gen collection evacuates both the YG and the\ncompactee. It will mark long lived roots and update pointers based on the\npreviously dirtied cards. Combining compaction with YG collections lets us\nshare the overhead of updating roots, and lets us avoid tracking pointers from\nthe YG into the compactee."),(0,i.kt)("li",{parentName:"ol"},"The now empty segment is released by the GC and returned to the OS.")),(0,i.kt)("h2",{id:"incremental-mode"},"Incremental Mode"),(0,i.kt)("p",null,"Hades's concurrent marking relies on being able to read a 64-bit value\natomically at the same time it might be modified by the mutator. If the\nunderlying hardware supports this natively, then we use it.\nHowever, some hardware does not support doing those atomic reads in a lock-free\nmanner, primarily 32-bit ARM CPUs. Since Hermes's main target is mobile devices,\nit's important for us to still support them, and have some of the fast pause\ntime guarantees that Hades gives."),(0,i.kt)("p",null,'In order to do this, on 32-bit platforms we don\'t use any other threads, and\ninstead run Hades in "incremental mode". This means instead of marking objects\nconcurrently on the GC thread, we use a portion of each YG GC to do some OG GC\nwork. This means the OG GC is completed incrementally on each individual YG GC.\nEach YG GC takes a little bit longer while an OG GC is active, but the penalty\nis small enough to still have better guarantees than running a fully blocking OG\nGC.'),(0,i.kt)("p",null,"The concurrent mode of Hades has faster pauses and is preferred to be used if\npossible, but incremental mode has to be used on most 32-bit CPUs. You can also\nuse incremental mode if threads aren't supported on your platform, or if you\nprefer to not use threads for some other reason."))}m.isMDXComponent=!0}}]);